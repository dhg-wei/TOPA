{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c553af76-f0dd-46ac-bd80-40d998cd5101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd773412-7424-4a0a-bb31-9ab1cc62ccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/home/users/nus/idmwyk/scratch/exp/data/videos/msrvtt/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e1f5140-ffbe-424e-a37a-147abd97d0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = os.path.join(dataset_path,'test_videodatainfo.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dee73cc8-9d0c-4ecf-89b7-8fc5c6bf73a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_file,'r') as f:\n",
    "    test_info = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb7498c0-62bf-423e-b318-f2afea9bed1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_gt = {}\n",
    "annotations_gt['images'] = test_info['videos']\n",
    "\n",
    "for sentence in test_info['sentences']:\n",
    "    sentence['image_id'] = int(sentence['video_id'].replace('video',''))\n",
    "    sentence['id'] = sentence['video_id']\n",
    "annotations_gt['annotations'] =test_info['sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "26d869de-8d18-45a9-a654-a1c695d42bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def sample_images_from_video(video_path, num_samples=10):\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Get the total number of frames in the video\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # Calculate total duration in seconds\n",
    "    total_duration = total_frames / frame_rate\n",
    "    print(total_duration)\n",
    "    # Check if the video opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video file.\")\n",
    "        return []\n",
    "\n",
    "    # Calculate the interval for sampling\n",
    "    interval = total_frames // num_samples\n",
    "\n",
    "    # Initialize a list to store the sampled images\n",
    "    sampled_images = []\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        # Set the frame position\n",
    "        frame_id = i * interval\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_id)\n",
    "\n",
    "        # Read the frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # If frame reading was successful, save the frame\n",
    "        if ret:\n",
    "            sampled_images.append(frame)\n",
    "        else:\n",
    "            print(f\"Error reading frame at position {frame_id}\")\n",
    "\n",
    "    # Release the video capture object\n",
    "    cap.release()\n",
    "\n",
    "    return sampled_images, total_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "095daa10-ee79-47cf-ae11-99298163bc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocoevalcap.eval import COCOEvalCap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b54e1096-f66f-4491-8d6a-d7da0f24baaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from json import encoder\n",
    "encoder.FLOAT_REPR = lambda o: format(o, '.3f')\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7917d97-37e0-4151-a287-deab470c1636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.06s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "annotation_file = os.path.join(dataset_path,'annotation_file')\n",
    "with open(annotation_file,'w') as f:\n",
    "    json.dump(annotations_gt,f)\n",
    "coco = COCO(annotation_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cccee5df-a00f-4978-8ab4-844dc7d50b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ids = coco.getImgIds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e8da968-9a55-4cdb-9197-9b36eef99599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2990"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(video_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2becdadc-b065-4e6e-a00a-c81de5c4acaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for video in video_ids:\n",
    "    results.append({'image_id':video,'caption': 'a video'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e305f8d4-4974-4b1a-a4cc-a77588de16ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6dbccd2b-97bd-47b9-b020-84f29e27d650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 617049 tokens at 2968232.24 tokens per second.\n",
      "PTBTokenizer tokenized 8969 tokens at 180713.53 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 5980, 'reflen': 16015, 'guess': [5980, 2990, 0, 0], 'correct': [4514, 869, 0, 0]}\n",
      "ratio: 0.3733999375585155\n",
      "Bleu_1: 0.141\n",
      "Bleu_2: 0.087\n",
      "Bleu_3: 0.001\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.080\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.302\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.022\n",
      "computing SPICE score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [0.8 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Threads( StanfordCoreNLP ) [20.548 seconds]\n",
      "Threads( StanfordCoreNLP ) [17.659 seconds]\n",
      "Threads( StanfordCoreNLP ) [16.367 seconds]\n",
      "Threads( StanfordCoreNLP ) [15.699 seconds]\n",
      "Threads( StanfordCoreNLP ) [15.330 seconds]\n",
      "Threads( StanfordCoreNLP ) [16.526 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [2.825 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 2.058 min\n",
      "SPICE: 0.016\n",
      "Bleu_1: 0.141\n",
      "Bleu_2: 0.087\n",
      "Bleu_3: 0.001\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.080\n",
      "ROUGE_L: 0.302\n",
      "CIDEr: 0.022\n",
      "SPICE: 0.016\n"
     ]
    }
   ],
   "source": [
    "coco_result = coco.loadRes(results) \n",
    "\n",
    "coco_eval = COCOEvalCap(coco, coco_result)\n",
    "coco_eval.evaluate()\n",
    "# print output evaluation scores\n",
    "for metric, score in coco_eval.eval.items():\n",
    "    print(f\"{metric}: {score:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "llama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
