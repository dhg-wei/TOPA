# TOPA
TOPA: Extend Large Language Models for Video Understanding via Text-Only Pre-Alignment

[arXiv](https://www.arxiv.org/pdf/2405.13911)

The code, pre-trained model, and data will be released in **June**.

## TODO:

Data

Pretrained models



# Acknowledgement
This repo benefits from [Flipped-VQA](https://github.com/mlvlab/Flipped-VQA), [LLaMA-Adapter](https://github.com/OpenGVLab/LLaMA-Adapter), [LLama2](https://github.com/meta-llama/llama) and [LLama3](https://github.com/meta-llama/llama3).
